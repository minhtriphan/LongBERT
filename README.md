# LongBERT
Implementation of the BERT model using LongNet

Some remarks:
* The data used is in the Huggingface `datasets` format (arrow format, generated by the `save_to_disk()` method);
* 

Instructions to train the model
1. Download the datasets
```
kaggle datasets download -d shinomoriaoshi/10-x-filings-train-part-1
kaggle datasets download -d shinomoriaoshi/10x-filings-train-part-2
kaggle datasets download -d shinomoriaoshi/10x-filings-valid
mkdir data
unzip 10-x-filings-train-part-1.zip -d data/train_part_1
unzip 10x-filings-train-part-2.zip -d data/train_part_2
unzip 10x-filings-valid.zip -d data/valid
```

2. Run
```
python main.py \
    --seed 1 \
    --ver v1a \
    --use_log 0 \
    --use_tqdm 1 \
    --backbone ./tokenizer \
    --max_len 10_000 \
    --nepochs 5 \
    --batch_size 4 \
    --train_data_dir /notebooks/data/train_part_1 \
    --valid_data_dir /notebooks/data/train_part_1
```
